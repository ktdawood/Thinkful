{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Challenge- Sentiment analysis for Amazon reviews.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqp9EqHkesNr",
        "colab_type": "text"
      },
      "source": [
        "# Amazon Reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udNfmq8desN7",
        "colab_type": "text"
      },
      "source": [
        "Now that you've looked at an example of how we can use Spark in batch mode, it's time to try it out on your own.\n",
        "\n",
        "In this challenge you'll work on a sentiment analysis dataset: the [Amazon reviews dataset](http://jmcauley.ucsd.edu/data/amazon/). You should choose one of the 5-core datasets. Keep in mind that if the data is g-zipped, you'll need to unpack the dataset before you use it.\n",
        "\n",
        "You should complete this challenge in a Jupyter notebook, which you'll need to work on Colab.\n",
        "\n",
        "Now, on to the task at hand!\n",
        "\n",
        "It's always important to start with a clear goal in mind. In this case, we'd like to determine if we can predict whether a review is positive or negative based on the language in the review.\n",
        "\n",
        "We're going to tackle this problem with Spark, so you'll need to apply the principles you've learned thus far in the context of Spark.\n",
        "\n",
        "Some tips to help you get started:\n",
        "\n",
        "Don't forget to install Java, Spark, Findspark and PySpark. You may also need to re-mount your drive to Colab. You can use the codes from the previous assignment for this purpose.\n",
        "Pyspark always needs to point at a running Spark instance. You can do that using a SparkContext.\n",
        "We're working in batch mode, so you'll need to load an entire file into memory in order to run any models you build."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWCwXLuUesOA",
        "colab_type": "text"
      },
      "source": [
        "# Objective\n",
        "\n",
        "Predict whether a review is positive or negative based on the language in the review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k80fQAB1esOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import sklearn\n",
        "import functools\n",
        "import json\n",
        "import gzip\n",
        "from urllib.request import urlopen\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FLgMIexe3sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spark and Colab Setup\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGYUrggfZZ_",
        "colab_type": "code",
        "outputId": "18b238bf-3477-46a6-cc53-eeb1c1ff86c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 68kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 68.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=730f3fe24801bf45be1886b1aab7ff96f232d86b97d539259f3fef3aeb59c80e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEtcfjd7fgdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OMeXKwjfjdm",
        "colab_type": "code",
        "outputId": "1f02542c-85ca-4490-b78d-12c2ede88960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOs95zNPZ8ni",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing/Predicting Sentiment From Amazon Reviews¶\n",
        "\n",
        "For this exercise, let's go back to the sentiment analysis we did earlier in the course - specifically, the Amazon reviews dataset.\n",
        "\n",
        "It's important to start with a clear goal in mind. In this case, we'd like to determine if we can predict whether a review is positive or negative based on the language in the review.\n",
        "\n",
        "We're going to tackle this problem with Spark - so you'll need to apply the principles you've learned thus far in the context of Spark.\n",
        "\n",
        "Some tips to help you get started:\n",
        "\n",
        "Pyspark always needs to point at a running Spark instance. You can do that using a SparkContext.\n",
        "We're still working in batch mode, so you'll need to load an entire file into memory in order to run any models you build.\n",
        "Spark likes to execute models in a pipeline, so remember that when the time comes to set up your model.\n",
        "Spark's machine learning algorithms expect numeric variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ZCavWsesOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dependencies\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "from pyspark.sql.functions import UserDefinedFunction\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2cFzK-VhUuM",
        "colab_type": "code",
        "outputId": "fc28782e-da8c-4e90-e8fa-fc45b27cda67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'gdrive',\n",
              " 'spark-2.4.5-bin-hadoop2.7.tgz',\n",
              " 'spark-2.4.5-bin-hadoop2.7',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ-Xc9WGesOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we use a set of constants for clarity and simplicity in managing the notebook.\n",
        "# this allows you to refer back to this cell at any time if you need to either confirm or modify any of these values.\n",
        "\n",
        "DATA_NAME = \"/content/gdrive/My Drive/Colab Datasets/AmznInstantVideo.json\"\n",
        "APP_NAME = \"Sentiment Analysis with Amazon Reviews Exercise\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "RANDOM_SEED = 141107\n",
        "TRAINING_DATA_RATIO = 0.8\n",
        "RF_NUM_TREES = 10\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRy9WMcaKpc",
        "colab_type": "text"
      },
      "source": [
        "The first thing we always do is create a SparkContext, and then immediately afterward create a sqlContext to be able to load and manipulate an RDD/dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asgMzQyGesPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Spark and SQL context\n",
        "sc = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QC0FUIaTXu",
        "colab_type": "text"
      },
      "source": [
        "Now that we've connected to Spark and have a sqlContext ready, it's time to load our data.\n",
        "\n",
        "We assume that you've already checked over some of the data, understand its type, and expected values/lengths before you get here.\n",
        "\n",
        "Luckily this is a simple exercise - this is a JSON file and all we need to do is load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZmzKHKDesPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the file into a DataFrame\n",
        "amznInstantVideo = sqlContext.read.json(DATA_NAME) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE9JhgXeaaKF",
        "colab_type": "text"
      },
      "source": [
        "Let's check the shape of the dataset, and review the schema so we see what we're dealing with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3nvIcFaeoe",
        "colab_type": "code",
        "outputId": "1a7bd450-2ec9-4838-bc9f-2827e952633f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(f\"Dataset shape is {amznInstantVideo.count():d} rows by {len(amznInstantVideo.columns):d} columns.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is 37121 rows by 10 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ALDux9esPb",
        "colab_type": "code",
        "outputId": "97a31a86-e690-4170-e279-0d6f4376d300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "amznInstantVideo.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(asin='B000H00VBQ', helpful=[0, 0], overall=2.0, reviewText=\"I had big expectations because I love English TV, in particular Investigative and detective stuff but this guy is really boring. It didn't appeal to me at all.\", reviewTime='05 3, 2014', reviewerID='A11N155CW1UV02', reviewerName='AdrianaM', summary='A little bit boring for me', unixReviewTime=1399075200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SULMpVp_esPu",
        "colab_type": "code",
        "outputId": "4bae921e-4eb2-4272-cfda-2af7ef67dd1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "amznInstantVideo.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSvGNsvva4yq",
        "colab_type": "text"
      },
      "source": [
        "Our schema shows that there is hope for our problem. Specifically, there are two columns that look interesting, and potentially a third:\n",
        "\n",
        "- **overall**: this looks like where we're keeping the starred review - on a scale of 1 to 5. We can make a decision on how we want to handle this in our model.\n",
        "- **reviewText**: This looks like it's the actual text of the review - we need to figure out from this whether or not it is positive or negative.\n",
        "- **summary**: This could also be helpful, but we need to understand what it is.\n",
        "\n",
        "Based on this cursory review of the dataset, we can see that we should be able to prepare this data such that we can use a classifier to model the sentiment (positive/negative) of the dataset.\n",
        "\n",
        "There are two data preparation steps we'll need to do before we run our model:\n",
        "\n",
        "1. Decide whether to recode our overall column into a more limited variable - either simply `positive/negative` or `positive/neutral/negative`\n",
        "2. Convert the text of each review into a numerical vector. Pyspark offers a number of methods to do this - we'll use **Word2Vec**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvWrdyOjbUJE",
        "colab_type": "text"
      },
      "source": [
        "Before we get going on our data preparation, let's take a look at the columns we mentioned above.\n",
        "\n",
        "To perform a SQL query on a dataframe, we need to create a **tempTable**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYdNQnEnesP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SQL\n",
        "amznInstantVideo.registerTempTable('reviews')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm4QNma-esQR",
        "colab_type": "code",
        "outputId": "4df09b7b-e035-493d-ffe5-417175347ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sqlContext.sql(\"select overall, count(overall) as reviewCount from reviews group by overall order by overall desc\").show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+\n",
            "|overall|reviewCount|\n",
            "+-------+-----------+\n",
            "|    5.0|      20888|\n",
            "|    4.0|       8445|\n",
            "|    3.0|       4185|\n",
            "|    2.0|       1885|\n",
            "|    1.0|       1718|\n",
            "+-------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCdac9Xbbd3r",
        "colab_type": "text"
      },
      "source": [
        "We see that most of the reviews are 5-star - so we certainly should recode. For our purposes, we can get closer to a balanced dataset if we recode to >3 is positive, <= 3 is negative.\n",
        "\n",
        "It's a bit of a stretch but a decent first pass.\n",
        "\n",
        "(Later, if you want to improve your classifier's performance, you could apply a resampling method to help balance the dataset).\n",
        "\n",
        "Let's recode the overall score to **positive** or **negative**\n",
        "\n",
        "- Positive: overall > 3\n",
        "- Negative: overall <= 3\n",
        "\n",
        "The easiest path to recoding the data in this fashion is to create a new column, from a User Defined Function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJJYWP_1esQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "udf = UserDefinedFunction(lambda x: 1 if x > 3.0 else -1, IntegerType())\n",
        "\n",
        "amznInstantVideo = amznInstantVideo.withColumn(\"overall_recode\",udf(amznInstantVideo.overall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqQ2VJA6btY2",
        "colab_type": "text"
      },
      "source": [
        "This time let's just make a plot of the two labels - so we can see the imbalance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoefXL70esQr",
        "colab_type": "code",
        "outputId": "727ca685-1274-436e-f0b1-df8fa6bd9d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Plotting\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15, 6)\n",
        " \n",
        "statuses = amznInstantVideo.groupBy('overall_recode').count().collect()\n",
        "\n",
        "categories = [i[0] for i in statuses]\n",
        "counts = [i[1] for i in statuses]\n",
        " \n",
        "ind = np.array(range(len(categories)))\n",
        "width = 0.35\n",
        "plt.bar(ind, counts, width=width, color='r')\n",
        " \n",
        "plt.ylabel('counts')\n",
        "plt.title('distribution')\n",
        "plt.xticks(ind + width/2., categories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7feec44a3898>,\n",
              "  <matplotlib.axis.XTick at 0x7feec4ccfe10>],\n",
              " <a list of 2 Text xticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4cAAAF1CAYAAABbKJ+tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABEOAQAASPL/AbxgBQ5pHxMZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUSM0T8qcEsy",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to look at the text and encode it into vectors.\n",
        "\n",
        "First, let's take a look at the relevant columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymajALIYesQ4",
        "colab_type": "code",
        "outputId": "1690fa26-f615-433c-ee7e-96edb4076aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "amznInstantVideo.select(\"overall\", \"overall_recode\", \"summary\", \"reviewText\").show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------+--------------------+--------------------+\n",
            "|overall|overall_recode|             summary|          reviewText|\n",
            "+-------+--------------+--------------------+--------------------+\n",
            "|    2.0|            -1|A little bit bori...|I had big expecta...|\n",
            "|    5.0|             1|Excellent Grown U...|I highly recommen...|\n",
            "|    1.0|            -1|Way too boring fo...|This one is a rea...|\n",
            "|    4.0|             1|Robson Green is m...|Mysteries are int...|\n",
            "|    5.0|             1|Robson green and ...|This show always ...|\n",
            "|    5.0|             1|I purchased the s...|I discovered this...|\n",
            "|    3.0|            -1|It takes up your ...|It beats watching...|\n",
            "|    3.0|            -1|A reasonable way ...|There are many ep...|\n",
            "|    5.0|             1|           kansas001|This is the best ...|\n",
            "|    3.0|            -1| Entertaining Comedy|Not bad.  Didn't ...|\n",
            "+-------+--------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtMkwsaScQzB",
        "colab_type": "text"
      },
      "source": [
        "For the start of this exercise we'll use only the reviewText column; later we could even merge the summary and reviewText to see if it improves the performance of the classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4_aYatIesRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokenized_text\").transform(amznInstantVideo)\n",
        "\n",
        "word2Vec = Word2Vec(vectorSize=300, seed=42, inputCol=\"tokenized_text\", outputCol=\"w2v_vector\").fit(tokenizer)\n",
        "\n",
        "w2vdf=word2Vec.transform(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIEoFmCesRb",
        "colab_type": "code",
        "outputId": "d2c13e23-ef85-4f7e-80e8-f0628473ca23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "w2vdf.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            " |-- overall_recode: integer (nullable = true)\n",
            " |-- tokenized_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- w2v_vector: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x69CGb49d1dS",
        "colab_type": "code",
        "outputId": "fd060f38-0146-4e5b-b36b-ee60a169c671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "w2vdf.select(\"overall_recode\", \"reviewText\", \"tokenized_text\", \"w2v_vector\").show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+--------------------+--------------------+\n",
            "|overall_recode|          reviewText|      tokenized_text|          w2v_vector|\n",
            "+--------------+--------------------+--------------------+--------------------+\n",
            "|            -1|I had big expecta...|[i, had, big, exp...|[-0.0386027075583...|\n",
            "|             1|I highly recommen...|[i, highly, recom...|[0.03085500549059...|\n",
            "|            -1|This one is a rea...|[this, one, is, a...|[0.00350296836292...|\n",
            "|             1|Mysteries are int...|[mysteries, are, ...|[0.00306359282694...|\n",
            "|             1|This show always ...|[this, show, alwa...|[0.00180407294192...|\n",
            "|             1|I discovered this...|[i, discovered, t...|[0.00200728614325...|\n",
            "|            -1|It beats watching...|[it, beats, watch...|[-0.0376871883403...|\n",
            "|            -1|There are many ep...|[there, are, many...|[-0.0319872667490...|\n",
            "|             1|This is the best ...|[this, is, the, b...|[-0.0174919149108...|\n",
            "|            -1|Not bad.  Didn't ...|[not, bad., , did...|[-0.0208042743357...|\n",
            "+--------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F51ce68teTPK",
        "colab_type": "text"
      },
      "source": [
        "Since we have everything in numeric format, let's start with our old standby, the random forest. You can choose other classifiers to see how they perform, and even chain them together and use their collective predictions in an ensemble to improve model performance.\n",
        "\n",
        "Important - note that your data is now in the w2vdf object - not the amznInstantVideo object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMvqjoJ2eUVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the training indexers/split data/classifier first we'll generate a labelIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"overall_recode\", outputCol=\"indexedLabel\").fit(w2vdf)\n",
        "\n",
        "# now generate the indexed feature vector.\n",
        "featureIndexer = VectorIndexer(inputCol=\"w2v_vector\", outputCol=\"indexedFeatures\", maxCategories=4).fit(w2vdf)\n",
        "\n",
        "# Split the data into training and validation sets (30% held out for testing)\n",
        "(trainingData, testData) = w2vdf.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ2e8fUYgJNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model. This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hsjOiugfYY",
        "colab_type": "code",
        "outputId": "97570bf2-89a5-4361-9d64-2c6b123014ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Select (prediction, true_label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.211623\n",
            "Accuracy = 0.788377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lrCL9IQhZCX",
        "colab_type": "text"
      },
      "source": [
        "We didn't do so well... but that's typical in data science work.\n",
        "\n",
        "Here's where you can go from here:\n",
        "\n",
        "1. Think about resampling the overall dataset to better balance positive and negative reviews.\n",
        "2. Use a different method to tokenize and convert the text to numeric (TF/IDF, etc).\n",
        "3. Adjust the parameters of your classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PYbfDBxhfsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}